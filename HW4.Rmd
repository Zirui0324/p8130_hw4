---
title: "HW4"
output: html_document
date: "2022-11-12"
---

```{r message=FALSE}
library(tidyverse)
library(BSDA)
library(readxl)
library(readr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE)
```

## Problem1

```{r}
blood_data = c(125, 123, 117, 123, 115, 112, 128, 118, 124, 111, 116, 109, 125, 120, 113, 123, 112, 118, 121, 118, 122, 115, 105, 118, 131)
blood_test_data = blood_data - 120
test1 = SIGN.test(blood_test_data, alternative = "less", conf.level = 0.95)
```

### a)
  According to the sign-test above, we can see that the test statistic is **`r test1$statistic`** with p-value **`r test1$p.value`**. Thus we fail to reject the null hypothesis under a 0.05 significant level and claim that the median blood sugar readings was 120 in the population from which the 25 patients were selected.
 
```{r}
test2 = wilcox.test(blood_test_data, alternative = "less", conf.level = 0.95)
``` 

### b)

  According to Wilcoxon signed-rank test, we can see that the test statistic is **`r test2$statistic`** with p-value **`r test2$p.value`**. Thus we fail to reject the null hypothesis under a 0.05 significant level and claim that the median blood sugar readings was 120 in the population from which the 25 patients were selected.
  
  
## Problem 2
```{r}
brain_data = 
  read_xlsx("./Brain.xlsx")[-c(1),] %>% 
  janitor::clean_names()

brain_fit = 
  lm(glia_neuron_ratio ~ ln_brain_mass, data = brain_data) 

brain_fit %>% 
  broom::tidy()
```

### a)

  The linear model for the nonhuman data using ln (brain mass) as the predictor is : **y = 0.181x + 0.164**.

```{r}
y_0 = 0.181*7.22 + 0.164
```

### b)

  The predicted glia-neuron ratio for humans is **`r y_0`**.

### c)

  I assume the most plausible range of values for the prediction is an interval for the prediction of a single new observation.
  
### d)

```{r}
new.data = data.frame(ln_brain_mass = 7.22)
predict(brain_fit, newdata = new.data, interval = "prediction", level = 0.95)
```

The 95% prediction interval for human glia-neuron ratio is **(1.04, 1.91)**. Based on this result, we can conclude that human brain doesn't have an excessive glia-neuron ratio for its mass compared with other primates.

### e)

Considering the position of the human data point relative to those data used to generate the regression line, we are not certain that the regression line could be used to predict the glia_neuron ratio of humans, as this point falls beyond the range of the variable used to fit the line.


## Problem 3
```{r}
heart_data = 
  read.csv("./HeartDisease.csv") %>% 
  mutate(
    gender = as.factor(gender),
    gender = recode(gender, "0" = "otherwise", "1" = "male")
         )
  
```

### a)

  The main predictor of this dataset is **total cost**, The main outcome is **number of emergency room visits**.
  Other important covariates: **age, gender, complications, duration**.
  Here are some descriptions of the important variables:
  
```{r}
summary(heart_data$totalcost)
summary(heart_data$ERvisits)
summary(heart_data$age)
summary(heart_data$complications)
summary(heart_data$duration)

gender_sum = 
  heart_data %>% 
  group_by(gender) %>% 
  summarise(count = n())

  barplot(height = gender_sum$count,
          names = gender_sum$gender)
```


### b)

```{r}
hist(heart_data$totalcost, xlab = "Total Cost", breaks = 100)
hist((heart_data$totalcost)^2, xlab = "ln(Total Cost)", breaks = 100)
hist((heart_data$totalcost)^(-1), xlab = "ln(Total Cost)", breaks = 100)
hist(log(heart_data$totalcost), xlab = "ln(Total Cost)", breaks = 100)
```

It seems that the plot best fits normality after ln-transformation.

```{r}
heart_data = 
  heart_data %>% 
  filter(totalcost > 0) %>% 
  mutate(ln_cost = log(totalcost))

shapiro.test(heart_data$ln_cost)
```
  
The Shapiro Test shows that total cost data doesn't follow normal distribution after ln-transformation.

### c)

```{r }
heart_data = 
  heart_data %>% 
  mutate(
    comp_bin = 
      case_when(
        complications == 0 ~ "0",
        TRUE ~ "1"
      ))
```

### d)

```{r}
heart_data %>% 
  ggplot()+
  geom_point(aes(x = ERvisits, y = ln_cost))+
  theme_bw()+
  labs(x = "Number of Emergency Room Visits",
       y = "ln(Total Cost)")

heart_fit = 
  lm(ln_cost ~ ERvisits, data = heart_data)

summary(heart_fit)

t_cri = qt(p=.05/2, df=783, lower.tail=FALSE)
t_cri
```
The slope is 0.22672, at a 5% significance level, t > t783,0.975, we reject the null and conclude that there is a significant linear association between the number of Emergency room visits and ln(Total cost). Which also means that holding all other variable constantm, as the risk of ERvisits goes up by 1 percent point, the predicted ln(Total cost) will increase by approximately 0.22672 dollars.

### e)

1)
  
```{r}
fit_inter = 
  lm(totalcost ~ ERvisits*comp_bin, data = heart_data)
summary(fit_inter)
```

  We can tell from the test above that comp_bin is not an effect modifier of the relationship between totalcost and ERvisit, as the p-value for the coefficient of ERvisits:comp_bin is not significant.

2)

```{r}
fit_1 = 
  lm(ln_cost ~ ERvisits, data = heart_data)
fit_2 = 
  lm(ln_cost ~ ERvisits + comp_bin, data = heart_data)
fit_1$coefficients
fit_2$coefficients
```

  The coefficients of ERvisits in the regression model with or without comp_bin did not show much difference, indicating that comp_bin might no be considered a confounder of the relationship between totalcost and ERvisits.

3)

```{r}
fit_2|>anova()
```

From the ANOVA test above we can tell that comp_bin should be included with ERvisits as the p-value for the coefficient of comp_bin is less than 0.05 after adding it as an additional variable to the regression model.
  
### f)

1)
  
```{r}
fit_more = 
  lm(ln_cost ~ ERvisits + comp_bin + age + gender + duration, data = heart_data) 
fit_more|>summary()
fit_more|>anova()
```

The fitted model is **ln(totalcost) = 6.0449619  + 0.1757486ERvisits + 1.4921110comp_bin + 0.0055406duration**. As the covariates **age and gender** didn't make any significant difference to the model under a 5% confidence level, they should not be included along with other variables.

2)

```{r} 
anova(fit_2, fit_more)
```

I would choose the MLR model, as the p-value of anova test is less than 0.05, we would reject the null hypotheses and conclude that the larger model is superior.
  

